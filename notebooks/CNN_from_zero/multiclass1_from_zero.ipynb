{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "37d4b555",
      "metadata": {
        "id": "37d4b555"
      },
      "source": [
        "# Deep Learning (TensorFlow, Keras): Image Multi-class Classifier (Part 1)\n",
        "In this project, a model is trained to perform multi-class classification for apple, banana and orange pictures. None pretrained model is used, the convolutiona neuronal network will be design from zero. This document is the first part of the whole training process.\n",
        "\n",
        "The dataset can be found in (805 MB):\n",
        "\n",
        "https://www.kaggle.com/datasets/shivamardeshna/fruits-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ad53e5c",
      "metadata": {},
      "source": [
        "## Iteration 1: CNN creation and training (learning_rate=1e-4) without data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fPgTDtJJyM24",
      "metadata": {
        "id": "fPgTDtJJyM24"
      },
      "outputs": [],
      "source": [
        "# (height, width, channels)\n",
        "input_shape = (224, 224, 3)\n",
        "batch_size = 12\n",
        "learning_rate = 1e-4\n",
        "path_dataset = '../../fruits_dataset'\n",
        "folder_apple = 'apple'\n",
        "folder_banana = 'banana'\n",
        "folder_orange = 'orange'\n",
        "folder_models = '../../models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25443748",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25443748",
        "outputId": "582675ae-9e70-4b92-8284-28cc33598c44"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, AvgPool2D,MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09197178",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09197178",
        "outputId": "170de5ea-d5a0-4ca6-cdf4-06a9a48d07e9"
      },
      "outputs": [],
      "source": [
        "# Find how many apple, banana, and orange images exist\n",
        "apple_imgs = os.listdir(os.path.join(path_dataset,folder_apple))\n",
        "banana_imgs = os.listdir(os.path.join(path_dataset,folder_banana))\n",
        "orange_imgs = os.listdir(os.path.join(path_dataset,folder_orange))\n",
        "print(f'Apple images found: {len(apple_imgs)}')\n",
        "print(f'Banana images found: {len(banana_imgs)}')\n",
        "print(f'Orange images found: {len(orange_imgs)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e82e440b",
      "metadata": {},
      "source": [
        "Classes are balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96948d32",
      "metadata": {},
      "source": [
        "### No Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7fa1120",
      "metadata": {
        "id": "f7fa1120"
      },
      "outputs": [],
      "source": [
        "def load_data(path, input_shape=input_shape, batch_size=batch_size, seed=123, validation_split=0.2):\n",
        "    \"\"\"Function to create 2 ImageDataGenerators to split dataset into train and validation datasets.\n",
        "    Data augmentation is not implemented for the validation dataset.\"\"\"\n",
        "    height, width = input_shape[:2]\n",
        "    datagen = ImageDataGenerator(rescale=1.0/255, zoom_range=0,\n",
        "        horizontal_flip=True, vertical_flip=False,\n",
        "        height_shift_range=0, width_shift_range=0,\n",
        "        brightness_range=(0.99, 1.0), rotation_range=0,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    train_data = datagen.flow_from_directory(path,\n",
        "        target_size=(height, width), batch_size=batch_size,\n",
        "        class_mode='sparse', subset='training', seed=seed\n",
        "    )\n",
        "    val_datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    val_data = val_datagen.flow_from_directory(path,\n",
        "        target_size=(height, width), batch_size=batch_size,\n",
        "        class_mode='sparse', subset='validation', seed=seed\n",
        "    )\n",
        "    return train_data, val_data\n",
        "\n",
        "# Split training and validation datasets\n",
        "train, val = load_data(path_dataset)\n",
        "\n",
        "print(f\"Classes found: {train.class_indices}\")\n",
        "print(f\"Training images: {train.samples}\")\n",
        "print(f\"Validation images: {val.samples}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adab49d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "adab49d2",
        "outputId": "1680a9bc-f757-46c3-e5b3-d006dc8b31ba"
      },
      "outputs": [],
      "source": [
        "# Obtain images and target\n",
        "images, labels = next(train)\n",
        "\n",
        "# Show 8 training images (batch_size=8)\n",
        "figure, axes = plt.subplots(nrows=2,ncols=4, figsize=(8, 6))\n",
        "for item in zip(axes.ravel(), images, labels):\n",
        "    axes, image, target = item\n",
        "    axes.imshow(image)\n",
        "    axes.set_title(f'Target: {target:0.0f}')\n",
        "    axes.set_xticks([])\n",
        "    axes.set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Image dimensions\n",
        "print(images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cf1fd9a",
      "metadata": {},
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b5e0c16",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(input_shape=input_shape, learning_rate=learning_rate):\n",
        "    \"\"\"Function to create a CNN model from scratch.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(6, (5, 5), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(AvgPool2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(16, (5, 5), padding='valid', activation='relu'))\n",
        "    model.add(AvgPool2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(16, (5, 5), padding='valid', activation='relu'))\n",
        "    model.add(AvgPool2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(3, activation='softmax'))           # 3 classes\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95e0b6cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_data, val_data, epochs, version_model):\n",
        "    \"\"\"Function to train the model and save the best one\n",
        "    according to the validation accuracy.\"\"\"\n",
        "    file_name = os.path.join(folder_models,f'sparse_model_v{version_model}.h5')\n",
        "    \n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=0),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=0),\n",
        "        ModelCheckpoint(file_name, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(train_data, validation_data=val_data,\n",
        "              epochs=epochs, callbacks=callbacks, verbose=2)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad1d77a",
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "version_model = 1\n",
        "print(f\"Parameters: batch_size = {batch_size}, learning_rate = {learning_rate}, epochs = {epochs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94852f1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94852f1b",
        "outputId": "8d916d06-3834-41b5-8c98-6f94a0bd0ac4"
      },
      "outputs": [],
      "source": [
        "# Create and train the model v1\n",
        "model = create_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d45008",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "\n",
        "# Ensure GPU is available\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
        "    print(\"GPU is available and memory growth is enabled.\")\n",
        "else:\n",
        "    print(\"GPU not available, training will be on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fef21f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model, history_stage1 = train_model(model, train, val, epochs=epochs, version_model=version_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "446c178c",
      "metadata": {
        "id": "446c178c"
      },
      "source": [
        "**Result 1:** val_accuracy=%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5281c28",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(history_stage1.history).plot(figsize=(12, 4))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a96191",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "# model.save(os.path.join(folder_models,f'binary_model_v{version_model}.keras'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d67d9e8",
      "metadata": {},
      "source": [
        "In the next iteration, the model will be retrained, data augmentation and fine-tuning (last 10 layers) will be performed."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env (3.8.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
